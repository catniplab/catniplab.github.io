---
layout: post
title:  Task representations in neural networks trained to perform many cognitive tasks (2019)
category: journalclub
olddate: November 04, 2020
---
 
*Guangyu Robert Yang, Madhura R. Joglekar, H. Francis Song, William T. Newsome, Xiao-Jing Wang*. Nature Neuroscience (2019) 
[(Nature Neuroscience)](https://www.nature.com/articles/s41593-018-0310-2)
[(local cache)]({{site.url}}/journalclub/JCpapers/yangTaskRepresentationsNeural2019.pdf)

#### Abstract
The brain has the ability to flexibly perform many tasks, but the underlying mechanism cannot be elucidated in traditional experimental and modeling studies designed for one task at a time. Here, we trained single network models to perform 20 cognitive tasks that depend on working memory, decision making, categorization, and inhibitory control. We found that after training, recurrent units can develop into clusters that are functionally specialized for different cognitive processes, and we introduce a simple yet effective measure to quantify relationships between single-unit neural representations of tasks. Learning often gives rise to compositionality of task representations, a critical feature for cognitive flexibility, whereby one task can be performed by recombining instructions for other tasks. Finally, networks developed mixed task selectivity similar to recorded prefrontal neurons after learning multiple tasks sequentially with a continual-learning technique. This work provides a computational platform to investigate neural representations of many cognitive tasks.